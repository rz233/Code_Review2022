{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8a07590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import plotly.express as px\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import argparse\n",
    "import pyarrow\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.figure_factory as ff\n",
    "from functools import reduce\n",
    "from datetime import datetime, timedelta, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3435a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"path/to/data\"\n",
    "outputs_path = \"output/path\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0029abd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class weekly_report:\n",
    "    \"\"\"\n",
    "\n",
    "    This class loads sensor data at hourly level and at daily level and creates\n",
    "    biweekly dashboard to monitor the violations and speed of each vehicle.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 folder_path,\n",
    "                 outputs_path,\n",
    "                 year,\n",
    "                 month,\n",
    "                 date\n",
    "                 ):\n",
    "        \"\"\"\n",
    "       Parameters\n",
    "       ----------\n",
    "       folder_path : Folder containing sensor data at hourly level and daily level \n",
    "       outputs_path : Folder to save outputs. \n",
    "       year: enter the year \n",
    "       month: enter the month\n",
    "       date: enter the date\n",
    "\n",
    "       \"\"\"\n",
    "\n",
    "        self.folder_path = folder_path\n",
    "        self.sensor_day_path = os.path.join(\n",
    "            self.folder_path, \"sensor_day.gz.parquet\")\n",
    "        self.sensor_dayhr_path = os.path.join(\n",
    "            self.folder_path, \"sensor_dayhr.gz.parquet\")\n",
    "\n",
    "        self.outputs_path = outputs_path\n",
    "        if not os.path.exists(self.outputs_path):\n",
    "            os.mkdir(self.outputs_path)\n",
    "\n",
    "        self.year = year\n",
    "        self.month = month\n",
    "        self.date = date\n",
    "\n",
    "        print('Loading data...')\n",
    "        self.load_data()\n",
    "\n",
    "        print('Aggregating data...')\n",
    "        self.agg_all_data()\n",
    "        self.agg_past_twowk_data()\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Load sensor data\n",
    "\n",
    "    def load_data(self):\n",
    "        self.sensor_dayhr_raw = pd.read_parquet(self.sensor_dayhr_path)\n",
    "        self.sensor_day_raw = pd.read_parquet(self.sensor_day_path)\n",
    "\n",
    "        # preprocess function: add week variable to each entry\n",
    "        def preprocess(df):\n",
    "            df = df.sort_values(['date'])\n",
    "            first_date = df.date.unique()[0]\n",
    "            last_date = df.date.unique()[-1]\n",
    "            num_days = abs(last_date - first_date).days + 1\n",
    "            num_weeks = (num_days // 7) + 1 if (num_days %\n",
    "                                                7) != 0 else num_days // 7\n",
    "            week_bin = pd.date_range(\n",
    "                df['date'].unique()[0], periods=num_weeks + 1, freq='168H')\n",
    "            labels = [i for i in range(1, len(week_bin))]\n",
    "            df[\"week\"] = pd.cut(df['date'].astype('datetime64[ns]'),\n",
    "                                week_bin, right=False, include_lowest=True, labels=labels)\n",
    "\n",
    "            df['route'] = df['route'].fillna('Missing')\n",
    "\n",
    "            return df\n",
    "\n",
    "        self.sensor_dayhr = preprocess(self.sensor_dayhr_raw)\n",
    "        self.sensor_day = preprocess(self.sensor_day_raw)\n",
    "\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # calculate the number of total violations(medium violation + extreme violation) \n",
    "    # per week and the number of extreme violations per week for each vehicle over \n",
    "    # the whole period of time \n",
    "    def agg_all_data(self):\n",
    "        self.totext_vio_perwk = self.sensor_day.groupby(['regno_clean', 'week']).\\\n",
    "            apply(lambda x:pd.Series({'total_vio': x['N_valueg_above0_3'].sum(),\n",
    "                    'ext_vio': x['N_valueg_above0_4'].sum()})).reset_index()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # only use past two week data to calculate: \n",
    "    # (1) the number of violation for each violation type for each vehicle\n",
    "    # (2) the number of total violations(medium violation + extreme violation) \n",
    "    # per day and the number of extreme violations per day for each vehicle \n",
    "    # (3) the number of violations per 100km for all vehicles\n",
    "    # (4) the number of violations per 100km for all vehicles(without outlier in distance)\n",
    "    # (5) 85th pert of speed each day each hr for each vehicle within same route\n",
    "    # (6) a summery table including the number of violation type; first & last online date in sensor data\n",
    "    # and first & last online date in eco data; and numbe of online days in past two weeks\n",
    "    def agg_past_twowk_data(self):\n",
    "        \n",
    "        self.start_date = date(self.year,self.month,self.date) - timedelta(days = 13)\n",
    "        self.past2wk_sensor_day = self.sensor_day[(self.sensor_day.date <= date(self.year,self.month,self.date)) &\\\n",
    "                                             (self.sensor_day.date >= self.start_date)]\n",
    "        \n",
    "        self.past2wk_sensor_dayhr = self.sensor_dayhr[(self.sensor_dayhr.date <= date(self.year,self.month,self.date)) &\\\n",
    "                                             (self.sensor_dayhr.date >= self.start_date)]\n",
    "        \n",
    "        \n",
    "        self.past2wk_viotype_cnt = self.past2wk_sensor_day.groupby(['regno_clean']).apply(lambda x: \\\n",
    "            pd.Series({'brake': x['N_valueg_above0_3_brake'].sum(),\n",
    "                      'turn': x['N_valueg_above0_3_turn'].sum(),\n",
    "                      'acceleration': x['N_valueg_above0_3_acceleration'].sum()})).reset_index()\n",
    "        \n",
    "        self.past2wk_totext_vio_perday = self.past2wk_sensor_day.groupby(['regno_clean','route' ,'date']).apply(lambda x: \\\n",
    "                            pd.Series({'total_vio': x['N_valueg_above0_3'].sum(),\n",
    "                            'ext_vio': x['N_valueg_above0_4'].sum()})).reset_index()\n",
    "            \n",
    "    \n",
    "        \n",
    "        def complete_time(df, timevar = 'datetime_eat', timefreq = 'H'):\n",
    "           \n",
    "            df[timevar] = df[timevar].astype('datetime64[ns, Africa/Nairobi]')\n",
    "                \n",
    "            df = df.sort_values(timevar)\n",
    "            full_time_range = pd.date_range(df[timevar].unique()[0],  \n",
    "                                    df[timevar].unique()[-1], \n",
    "                                            freq = timefreq)\n",
    "    \n",
    "            cpl_time = pd.DataFrame(full_time_range, columns = [timevar])\n",
    "            cpl_df = df.merge(cpl_time, how = 'outer')\n",
    "     \n",
    "            cpl_df['regno_clean'] = cpl_df['regno_clean'].fillna(cpl_df['regno_clean'][0])\n",
    "            cpl_df['route'] = cpl_df['route'].fillna(cpl_df['route'][0])\n",
    "            \n",
    "            if timevar == 'date':\n",
    "                cpl_df['date'] = pd.to_datetime(cpl_df['date']).dt.date\n",
    "    \n",
    "            return cpl_df\n",
    "    \n",
    "    \n",
    "        def complete_time_perveh(df, timevar = 'datetime_eat', timefreq = 'H'):\n",
    "           temp = pd.DataFrame()\n",
    "           uniq_vh = df.regno_clean.unique()\n",
    "           for vh in uniq_vh:\n",
    "               sample_vh = df[df.regno_clean == vh]\n",
    "               sample_vh = sample_vh.sort_values([timevar])\n",
    "               cpl_time_vh = complete_time(sample_vh, timevar, timefreq)\n",
    "               temp =temp.append(cpl_time_vh)\n",
    "   \n",
    "           temp = temp.sort_values(['regno_clean', timevar])\n",
    "           \n",
    "           return temp\n",
    "       \n",
    "      \n",
    "        self.speed_dayhr_past2wk = complete_time_perveh(self.past2wk_sensor_dayhr).\\\n",
    "        sort_values(['regno_clean','datetime_eat'])\n",
    "       \n",
    "        self.past2wk_totext_vio_perday = complete_time_perveh(self.past2wk_totext_vio_perday, 'date', 'D').\\\n",
    "        sort_values(['regno_clean','date'])\n",
    "    \n",
    "            \n",
    "    \n",
    "        # calculate total and extreme violations per 100 km per day\n",
    "        self.sd_totext_vio_past2wk = self.past2wk_sensor_day\n",
    "      \n",
    "        # remove the entries where the daily distance is NA\n",
    "        self.sd_totext_vio_past2wk = self.sd_totext_vio_past2wk[~(\n",
    "            self.sd_totext_vio_past2wk.distance_hourly_sum_km.isnull())]\n",
    "                                         \n",
    "    \n",
    "        #self.totext_vio_per100km_past2wk = self.sd_totext_vio_past2wk.\\\n",
    "        #    groupby(['regno_clean','route','date']).apply(lambda x: pd.Series({\n",
    "        #        'totvio_per_100km': (x['N_valueg_above0_3'].sum()/x['distance_hourly_sum_km'].sum())*100,\n",
    "        #        'extvio_per_100km': (x['N_valueg_above0_4'].sum()/x['distance_hourly_sum_km'].sum())*100\n",
    "        #        })).reset_index()\n",
    "    \n",
    "        #self.totext_vio_per100km_past2wk = complete_time_perveh(self.totext_vio_per100km_past2wk, \n",
    "        #timevar = 'date', timefreq = 'D').sort_values(['regno_clean','date'])\n",
    "    \n",
    "    \n",
    "        ## remove the entries where the distance is below 10\n",
    "        self.sd_totext_vio_past2wk_thre =  self.sd_totext_vio_past2wk[\n",
    "                                 self.sd_totext_vio_past2wk.distance_hourly_sum_km > 10]\n",
    "        \n",
    "        self.totext_vio_per100km_past2wk_thre = self.sd_totext_vio_past2wk_thre.\\\n",
    "        groupby(['regno_clean','route','date']).apply(lambda x: pd.Series({\n",
    "            'totvio_per_100km': (x['N_valueg_above0_3'].sum()/x['distance_hourly_sum_km'].sum())*100,\n",
    "            'extvio_per_100km': (x['N_valueg_above0_4'].sum()/x['distance_hourly_sum_km'].sum())*100\n",
    "        })).reset_index()\n",
    "        \n",
    "        self.totext_vio_per100km_past2wk_thre = complete_time_perveh(self.totext_vio_per100km_past2wk_thre, \n",
    "                                        timevar = 'date', timefreq = 'D').sort_values(['regno_clean','date'])\n",
    "                            \n",
    "        \n",
    "        ### summary table for past two weeks\n",
    "        def first_last_date(df, data_name):\n",
    "            ## get the first date each matatu is online\n",
    "            first_online_date = df.sort_values([\"regno_clean\",\"date\"]).groupby('regno_clean').\\\n",
    "            head(1)[[\"regno_clean\",\"date\"]].rename(columns = {'date': data_name +'1st_oldate'})\n",
    "            ## get the last date each matatu is online\n",
    "            last_online_date = df.sort_values([\"regno_clean\",\"date\"]).groupby('regno_clean').\\\n",
    "            tail(1)[[\"regno_clean\",\"date\"]].rename(columns = {'date': data_name + 'last_oldate'})\n",
    "            online_date = first_online_date.merge(last_online_date)\n",
    "            \n",
    "            return online_date\n",
    "        \n",
    "        # get the first and the last date each matatu is online in eco data\n",
    "        self.online_date_eco = first_last_date(self.sensor_day, 'eco')\n",
    "        \n",
    "        # get the first and the last date each matatu is online in sensor data\n",
    "        self.online_date_sensor = first_last_date(self.sensor_day[~(self.sensor_day['speed_min'].isna())], 'sns')\n",
    "        \n",
    "          \n",
    "        viocnt = self.past2wk_sensor_day.groupby(['regno_clean']).apply(lambda x: pd.Series({\n",
    "            'total_vio': x['N_valueg_above0_3'].sum(), 'ext_vio': x['N_valueg_above0_4'].sum(),\n",
    "            'acc_totcnt': x['N_valueg_above0_3_acceleration'].sum(), 'acc_extcnt':x['N_valueg_above0_4_acceleration'].sum(),\n",
    "            'turn_totcnt': x['N_valueg_above0_3_turn'].sum(), 'turn_extcnt':x['N_valueg_above0_4_turn'].sum(),\n",
    "            'brake_totcnt': x['N_valueg_above0_3_brake'].sum(), 'brake_extcnt':x['N_valueg_above0_4_brake'].sum()\n",
    "            })).reset_index()\n",
    "        \n",
    "        \n",
    "        self.summary_table1 = viocnt.merge(self.online_date_sensor).merge(self.online_date_eco)\n",
    "        \n",
    "        sensor_1stlastday_past2wk = self.past2wk_sensor_day[~(self.past2wk_sensor_day['speed_min'].isna())]\n",
    "        \n",
    "        self.past2wk_online_date_eco =  first_last_date(self.past2wk_sensor_day, 'eco')\n",
    "        self.past2wk_online_date_eco['eco_ndays'] = (self.past2wk_online_date_eco['ecolast_oldate'] - self.past2wk_online_date_eco['eco1st_oldate']).\\\n",
    "        dt.days + 1\n",
    "        \n",
    "        self.past2wk_online_date_sensor = first_last_date(sensor_1stlastday_past2wk, 'sns')\n",
    "        self.past2wk_online_date_sensor['sns_ndays'] = (self.past2wk_online_date_sensor['snslast_oldate'] - \\\n",
    "        self.past2wk_online_date_sensor['sns1st_oldate']).dt.days + 1\n",
    "        \n",
    "        self.summary_table_final = self.summary_table1.merge(self.past2wk_online_date_eco[['regno_clean','eco_ndays']]).\\\n",
    "            merge(self.past2wk_online_date_sensor[['regno_clean','sns_ndays']])\n",
    "    \n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # all data figures   \n",
    "    def hist_totvio_perwk(self, export = True):\n",
    "            fig = px.bar(self.totext_vio_perwk, x=\"week\", y = \"total_vio\" ,color = \"week\", \n",
    "                   facet_col=\"regno_clean\",facet_col_wrap = 4,\n",
    "                   labels = {\"total_vio\":\"Totvio\"},\n",
    "                   facet_row_spacing=0.015, # default is 0.07 when facet_col_wrap is used\n",
    "                   facet_col_spacing=0.04,# default is 0.03\n",
    "                   height=2800, width=1100)\n",
    "        \n",
    "                   \n",
    "            fig.update_layout(title_text=\"Number of total violation per week for all vehicles\")\n",
    "            \n",
    "            if export:\n",
    "                file_name = self.outputs_path + '/' + 'hist_totvio_wk_alldata.html'\n",
    "                print('Saving: ' + file_name)\n",
    "                plotly.offline.plot(fig, filename = file_name, auto_open=False)\n",
    "                \n",
    "                div = plotly.offline.plot(fig, filename = file_name, auto_open=False,\n",
    "                                    include_plotlyjs=False, output_type='div')\n",
    "                \n",
    "                return div\n",
    "                \n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # past two weeks figures\n",
    "    def hist_viotype_past2wk(self, export = True):\n",
    "        melt_df = pd.melt(self.past2wk_viotype_cnt,id_vars=['regno_clean'],\n",
    "                          value_vars =['brake','turn','acceleration'])\n",
    "        \n",
    "        fig = px.bar(melt_df, x=\"variable\", y = \"value\" ,color = \"variable\", \n",
    "                   facet_col=\"regno_clean\",facet_col_wrap = 4,\n",
    "                   labels = {\"variable\":\"Harsh event\", \"value\":\"cnt\"},\n",
    "                   title = \"Past two weeks: Number of violation types for all vehicles\",\n",
    "                   facet_row_spacing=0.015,facet_col_spacing=0.04,height=2000, width=1100)\n",
    "        \n",
    "        if export:\n",
    "            file_name = self.outputs_path + \"/hist_viotypecnt_past2wk.html\"\n",
    "            print('Saving: ' + file_name)\n",
    "            plotly.offline.plot(fig, filename = file_name, auto_open=False)\n",
    "\n",
    "            div = plotly.offline.plot(fig, filename = file_name, auto_open=False,\n",
    "                                    include_plotlyjs=False, output_type='div')\n",
    "                \n",
    "            return div\n",
    "    \n",
    "    \n",
    "    def line_totalext_vio_past2wk(self,export = True):\n",
    "        melt_df = pd.melt(self.past2wk_totext_vio_perday, id_vars=['regno_clean', 'date'],\n",
    "                          value_vars =['total_vio','ext_vio'])\n",
    "        \n",
    "        fig = px.line(melt_df, x='date', y='value', color = 'variable',\n",
    "                    facet_col ='regno_clean', facet_col_wrap = 4, \n",
    "                    facet_row_spacing=0.015, \n",
    "                    facet_col_spacing=0.04, \n",
    "                    height=2000, width=1200,\n",
    "                    labels = {'value':'cnt'},\n",
    "                    title= \"Past two weeks: Number of violations for all vehicles\")\n",
    "        fig.update_yaxes(rangemode=\"tozero\")\n",
    "        #fig.update_yaxes(matches=None)\n",
    "            \n",
    "        \n",
    "        if export:\n",
    "            file_name = self.outputs_path + '/' + 'total_extvio_past2wk.html'\n",
    "            print('Saving: ' + file_name)\n",
    "            plotly.offline.plot(fig, filename = file_name, auto_open=False)\n",
    "\n",
    "            div = plotly.offline.plot(fig, filename = file_name, auto_open=False,\n",
    "                                    include_plotlyjs=False, output_type='div')\n",
    "                \n",
    "            return div\n",
    "    \n",
    "    \n",
    "    def line_totalext_vio_per100km_past2wk(self, export = True):\n",
    "        melt_df = pd.melt(self.totext_vio_per100km_past2wk,\n",
    "                        id_vars = ['regno_clean','date'], \n",
    "                        value_vars = ['totvio_per_100km','extvio_per_100km'])\n",
    "        \n",
    "        fig = px.line(melt_df, x='date', y='value', color = 'variable',\n",
    "                    facet_col ='regno_clean', facet_col_wrap = 4, \n",
    "                    facet_row_spacing=0.015, \n",
    "                    facet_col_spacing=0.04, \n",
    "                    height=2300, width=1200,\n",
    "                    labels = {'value':'cnt'},\n",
    "                    title= \"Past two weeks: Number of violations per 100km for all vehicles\")\n",
    "        fig.update_yaxes(rangemode=\"tozero\")\n",
    "            #fig.update_yaxes(matches=None)\n",
    "            \n",
    "        \n",
    "        if export:\n",
    "            file_name = self.outputs_path + '/' + 'total_extvio_per_100km_past2wk2.html'\n",
    "            print('Saving: ' + file_name)\n",
    "            plotly.offline.plot(fig, filename = file_name, auto_open=False)\n",
    "            \n",
    "            div = plotly.offline.plot(fig, filename = file_name, auto_open=False,\n",
    "                                    include_plotlyjs=False, output_type='div')\n",
    "        \n",
    "            \n",
    "            \n",
    "            return div\n",
    "    \n",
    "    \n",
    "    def line_totalext_vio_per100km_past2wk_thre(self, export = True):\n",
    "        melt_df = pd.melt(self.totext_vio_per100km_past2wk_thre,\n",
    "                        id_vars = ['regno_clean','date'], \n",
    "                        value_vars = ['totvio_per_100km','extvio_per_100km'])\n",
    "        \n",
    "        fig = px.line(melt_df, x='date', y='value', color = 'variable',\n",
    "                    facet_col ='regno_clean', facet_col_wrap = 4, \n",
    "                    facet_row_spacing=0.015, \n",
    "                    facet_col_spacing=0.04, \n",
    "                    height=2300, width=1200,\n",
    "                    labels = {'value':'cnt'},\n",
    "                    title= \"Past two weeks: Number of violations per 100km for all vehicles (without outliers in distance)\")\n",
    "        fig.update_yaxes(rangemode=\"tozero\")\n",
    "            #fig.update_yaxes(matches=None)\n",
    "            \n",
    "        \n",
    "        if export:\n",
    "            file_name = self.outputs_path + '/' + 'total_extvio_per_100km_past2wk2_without_outlier.html'\n",
    "            print('Saving: ' + file_name)\n",
    "            plotly.offline.plot(fig, filename = file_name, auto_open=False)\n",
    "            \n",
    "            div = plotly.offline.plot(fig, filename = file_name, auto_open=False,\n",
    "                                    include_plotlyjs=False, output_type='div')\n",
    "        \n",
    "            \n",
    "            \n",
    "            return div\n",
    "                \n",
    "    \n",
    "    \n",
    "    def line_speed85_dayhr_route_past2wk(self, export = True):\n",
    "        uniq_route = self.speed_dayhr_past2wk.route.unique()\n",
    "        div_list = []\n",
    "        for r in uniq_route:\n",
    "            sp_df = self.speed_dayhr_past2wk[self.speed_dayhr_past2wk.route == r]\n",
    "            fig = px.line(sp_df, x='datetime_eat', y = \"speed_p85\",\n",
    "                   facet_col=\"regno_clean\", facet_col_wrap = 4, \n",
    "                   labels = {'datetime_eat': 'day and hour', 'speed_p85':' 85th speed'},\n",
    "                   title =  r + \": 85th percentile of speed each day each hour\",\n",
    "                   facet_row_spacing=0.04, facet_col_spacing=0.04, height=1000, width=1100\n",
    "                  )\n",
    "\n",
    "            fig.update_traces(connectgaps=False)\n",
    "            \n",
    "            file_name = self.outputs_path + '/line_85thspeed_hr_past2wk_' + r +'.html'\n",
    "            if export:\n",
    "                print('Saving: ' + file_name)\n",
    "                plotly.offline.plot(fig, filename = file_name, auto_open=False)\n",
    "                div = plotly.offline.plot(fig, filename = file_name, auto_open=False,\n",
    "                                    include_plotlyjs=False, output_type='div')\n",
    "                \n",
    "                div_list.append(div)\n",
    "                \n",
    "        return div_list\n",
    "    \n",
    "    \n",
    "    def summary_table(self, export = True):\n",
    "        fig = go.Figure(data=[go.Table(\n",
    "        header=dict(values=list(self.summary_table_final.columns),\n",
    "                fill_color='paleturquoise',\n",
    "                align='left'),\n",
    "        cells=dict(values=self.summary_table_final.transpose().values.tolist(),\n",
    "               fill_color='lavender',\n",
    "               align='left'))\n",
    "        ])\n",
    "\n",
    "        fig.update_layout(title_text=\"Past two weeks:\\nSummary of the data\")\n",
    "        fig.update_layout(width=1700, height=1000)\n",
    "\n",
    "        \n",
    "        if export:\n",
    "            file_name = self.outputs_path + '/' + 'report_viotype_spd_dt_past2wk.html'\n",
    "            print('Saving: ' + file_name)\n",
    "            plotly.offline.plot(fig, filename = file_name, auto_open=False)\n",
    "            div = plotly.offline.plot(fig, filename = file_name, auto_open=True,\n",
    "                                    include_plotlyjs=False, output_type='div')\n",
    "            return div\n",
    "    \n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # create a dashboard and export as a html file. The date in the title and filename need to \n",
    "    # change everytime\n",
    "    def return_all_figure_div(self):\n",
    "        div1 = self.hist_totvio_perwk()\n",
    "        div2 = self.hist_viotype_past2wk()\n",
    "        div3 = self.line_totalext_vio_past2wk()\n",
    "        #div4 = self.line_totalext_vio_per100km_past2wk()\n",
    "        div7 = self.line_totalext_vio_per100km_past2wk_thre()\n",
    "        div5 = self.line_speed85_dayhr_route_past2wk()\n",
    "        div6 = self.summary_table()\n",
    "        \n",
    "        \n",
    "        html_string = '''\n",
    "        <html>\n",
    "            <head>\n",
    "            <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>\n",
    "            </head>\n",
    "            <body>\n",
    "              <h1>Weekly Report: 6/08/2022 - 6/21/2022</h1>\n",
    "              \n",
    "              ''' + div1 + '''\n",
    "              ''' + div2 + '''\n",
    "              ''' + div3 + '''\n",
    "        \n",
    "              ''' + div7 + '''\n",
    "              ''' + div5[0] + '''\n",
    "              ''' + div5[1] + '''\n",
    "              ''' + div5[2] + '''\n",
    "              ''' + div5[3] + '''\n",
    "              ''' + div5[4] + '''\n",
    "              ''' + div5[5] + '''\n",
    "              ''' + div6 + '''\n",
    "          \n",
    "              \n",
    "              \n",
    "      \n",
    "            </body>\n",
    "        </html>'''\n",
    "\n",
    "        with open(self.outputs_path + \"/\" + \"weekly_report_20220608-20220621.html\", 'w') as f:\n",
    "            f.write(html_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a0166ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Aggregating data...\n"
     ]
    }
   ],
   "source": [
    "report = weekly_report(folder_path,outputs_path,2022,6,21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "839af3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving: C:/Users/wb575963/OneDrive - WBG/Tasks/Kenya/Weekly_report_20220608-20220621/hist_totvio_wk_alldata.html\n",
      "Saving: C:/Users/wb575963/OneDrive - WBG/Tasks/Kenya/Weekly_report_20220608-20220621/hist_viotypecnt_past2wk.html\n",
      "Saving: C:/Users/wb575963/OneDrive - WBG/Tasks/Kenya/Weekly_report_20220608-20220621/total_extvio_past2wk.html\n",
      "Saving: C:/Users/wb575963/OneDrive - WBG/Tasks/Kenya/Weekly_report_20220608-20220621/total_extvio_per_100km_past2wk2_without_outlier.html\n",
      "Saving: C:/Users/wb575963/OneDrive - WBG/Tasks/Kenya/Weekly_report_20220608-20220621/line_85thspeed_hr_past2wk_Missing.html\n",
      "Saving: C:/Users/wb575963/OneDrive - WBG/Tasks/Kenya/Weekly_report_20220608-20220621/line_85thspeed_hr_past2wk_Nairobi to Eldoret.html\n",
      "Saving: C:/Users/wb575963/OneDrive - WBG/Tasks/Kenya/Weekly_report_20220608-20220621/line_85thspeed_hr_past2wk_Nairobi to Meru.html\n",
      "Saving: C:/Users/wb575963/OneDrive - WBG/Tasks/Kenya/Weekly_report_20220608-20220621/line_85thspeed_hr_past2wk_Nairobi to Nakuru.html\n",
      "Saving: C:/Users/wb575963/OneDrive - WBG/Tasks/Kenya/Weekly_report_20220608-20220621/line_85thspeed_hr_past2wk_Nairobi to Narok.html\n",
      "Saving: C:/Users/wb575963/OneDrive - WBG/Tasks/Kenya/Weekly_report_20220608-20220621/line_85thspeed_hr_past2wk_Nairobi to Marsabit.html\n",
      "Saving: C:/Users/wb575963/OneDrive - WBG/Tasks/Kenya/Weekly_report_20220608-20220621/line_85thspeed_hr_past2wk_Nairobi to Namanga.html\n",
      "Saving: C:/Users/wb575963/OneDrive - WBG/Tasks/Kenya/Weekly_report_20220608-20220621/line_85thspeed_hr_past2wk_Nairobi to Mombasa.html\n",
      "Saving: C:/Users/wb575963/OneDrive - WBG/Tasks/Kenya/Weekly_report_20220608-20220621/report_viotype_spd_dt_past2wk.html\n"
     ]
    }
   ],
   "source": [
    "report.return_all_figure_div()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504e777c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
